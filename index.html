Projects:
	1. Vehicle real time Sensor Analysis-
		Problem Statement: Sensor Data of Six moths was provided, the aim was to reduce cost loss caused due earlier failure of components and false failure indication of any sensor(FP and FN) with priority keeping false negative. We have to develop a predictive model to minimize the error caused sensor reading.
		Task : Data Wrangling, Data Augmentation, Standardizing the data, Model Training, Hyperparameter Tuning, Model Validation and Checking Data Drift
		Tools : Mongo DB, Python, Machine Learning,Pytorch, Kafka, Github, streamlit
	
	2. Email analyser and extractor-
		Problem Statement : To Analyse and Extract details from an Email and sort them sequentially . This was to filter out spams/irrelevant Email from the Email received. The goal was to reduce False Negative (FN) and extract details like sender name, Language, intent of email,summary of email body and rate the criticality.
		Task : Data Augmentation, Synthetic Data Generation, Prompt Engineering, Prompt Tuning, Transfer Learning, Model Evaluation and Deployment
		Tools : Python, Excel, GPT-4, Github, CI/CD Pipeline, NLP, Jupyter Notebook, Streamlit, Azure Cloud Service
	
	3. Warehouse goods tracker-
		Problem Statement : To keep a record of goods in and out from the warehouse. We have to extract and keep record of P-Code from every products moving via conveyor belt
		Task : Capturing Image, Amplifying it, Reducing the Noise, Extracting the Details from Image
		Tools : Python,Regex, VS- Code, API, Transfer Learning,Deep Learning, Open CV, CNN, Streamlit.
	
	
	
Developed Gradient Boosting and Random Forest classification models with hyperparameter tuning using GridSearchCV; saved and deployed models using joblib for production-ready use.

Built a hybrid recommendation engine combining content-based filtering (TF-IDF, cosine similarity) and collaborative filtering (user-item interactions) to deliver personalized suggestions.

Conducted comprehensive Exploratory Data Analysis (EDA) across multiple datasets using Pandas, Seaborn, and automated profiling to identify key patterns, correlations, and anomalies.

Applied statistical hypothesis testing techniques including z-tests and t-tests to validate business assumptions and compare user group performance in experimental scenarios.

Implemented customer segmentation using K-Means clustering and evaluated optimal cluster counts using silhouette scores and elbow method.
Trained various classification models such as Logistic Regression, K-Nearest Neighbors, and Decision Trees, and evaluated performance using confusion matrix, precision, recall, and F1-score.

Leveraged NLP techniques including topic modeling with Latent Dirichlet Allocation (LDA) and visualized insights using word clouds for unstructured text datasets.

Applied Principal Component Analysis (PCA) for dimensionality reduction, improving model efficiency while maintaining data variance.

Performed time series forecasting using ARIMA and SARIMAX models to predict GDP trends for over 200 countries from 1960 to 2023, including preprocessing steps like stationarity checks and differencing.